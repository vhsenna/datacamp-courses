{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "english-telephone",
   "metadata": {},
   "source": [
    "## Finding consistency\n",
    "\n",
    "In this exercise and throughout this chapter, you'll be working with the `airlines` DataFrame which contains survey responses on the San Francisco Airport from airline customers.\n",
    "\n",
    "The DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction. Another DataFrame named `categories` was created, containing all correct possible values for the survey columns.\n",
    "\n",
    "In this exercise, you will use both of these DataFrames to find survey answers with inconsistent values, and drop them, effectively performing an outer and inner join on both these DataFrames as seen in the video exercise. The `pandas` package has been imported as `pd`, and the `airlines` and `categories` DataFrames.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Print the `categories` DataFrame and take a close look at all possible correct categories of the survey columns.\n",
    "2. Print the unique values of the survey columns in `airlines` using the `.unique()` method.\n",
    "3. Take a look at the output. Out of the `cleanliness`, `safety` and `satisfaction` columns, which one has an inconsistent category and what is it?\n",
    "4. Create a set out of the `cleanliness` column in `airlines` using `set()` and find the inconsistent category by finding the **difference** in the `cleanliness` column of `categories`.\n",
    "5. Find rows of `airlines` with a `cleanliness` value not in `categories` and print the output.\n",
    "6. Print the rows with the consistent categories of `cleanliness` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hidden-palestine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      cleanliness           safety          satisfaction\n",
      "0           Clean        Very safe        Very satisfied\n",
      "1  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
      "2         Average          Neutral               Neutral\n",
      "3  Somewhat dirty  Somewhat unsafe  Somewhat unsatisfied\n",
      "4           Dirty      Very unsafe      Very unsatisfied\n",
      "\n",
      "\n",
      "Cleanliness:  ['Clean' 'Average' 'Somewhat satisfied' 'Somewhat clean' 'Somewhat dirty'\n",
      " 'Dirty'] \n",
      "\n",
      "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
      "\n",
      "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satisfied' 'Somewhat unsatisfied'\n",
      " 'Very unsatisfied'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataframes\n",
    "airlines = pd.read_csv('airlines.csv')\n",
    "categories = pd.read_csv('categories.csv')\n",
    "\n",
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('\\n')\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), '\\n')\n",
    "print('Safety: ', airlines['safety'].unique(), '\\n')\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "opposed-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2992</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MIAMI</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>559.0</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>2913</td>\n",
       "      <td>Friday</td>\n",
       "      <td>TURKISH AIRLINES</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>Middle East</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>225.0</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>100</td>\n",
       "      <td>2321</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    id        day           airline  destination  dest_region  \\\n",
       "4            4  2992  Wednesday          AMERICAN        MIAMI      East US   \n",
       "17          18  2913     Friday  TURKISH AIRLINES     ISTANBUL  Middle East   \n",
       "89         100  2321  Wednesday         SOUTHWEST  LOS ANGELES      West US   \n",
       "\n",
       "   dest_size boarding_area   dept_time  wait_min         cleanliness  \\\n",
       "4        Hub   Gates 50-59  2018-12-31     559.0  Somewhat satisfied   \n",
       "17       Hub  Gates 91-102  2018-12-31     225.0  Somewhat satisfied   \n",
       "89       Hub   Gates 20-39  2018-12-31     130.0  Somewhat satisfied   \n",
       "\n",
       "           safety        satisfaction  \n",
       "4       Very safe  Somewhat satisfied  \n",
       "17      Very safe  Somewhat satisfied  \n",
       "89  Somewhat safe  Somewhat satisfied  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "airlines[cat_clean_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vietnamese-representative",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1351</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>UNITED INTL</td>\n",
       "      <td>KANSAI</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 91-102</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>Friday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>SAN JOSE DEL CABO</td>\n",
       "      <td>Canada/Mexico</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2820</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 40-48</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1157</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>634</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEWARK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>140.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2804</td>\n",
       "      <td>1475</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>NEW YORK-JFK</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 50-59</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>280.0</td>\n",
       "      <td>Somewhat clean</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2805</td>\n",
       "      <td>2222</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>SOUTHWEST</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>West US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 20-39</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>165.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2806</td>\n",
       "      <td>2684</td>\n",
       "      <td>Friday</td>\n",
       "      <td>UNITED</td>\n",
       "      <td>ORLANDO</td>\n",
       "      <td>East US</td>\n",
       "      <td>Hub</td>\n",
       "      <td>Gates 70-90</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2807</td>\n",
       "      <td>2549</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>JETBLUE</td>\n",
       "      <td>LONG BEACH</td>\n",
       "      <td>West US</td>\n",
       "      <td>Small</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Somewhat safe</td>\n",
       "      <td>Very satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2808</td>\n",
       "      <td>2162</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>CHINA EASTERN</td>\n",
       "      <td>QINGDAO</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Large</td>\n",
       "      <td>Gates 1-12</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>220.0</td>\n",
       "      <td>Clean</td>\n",
       "      <td>Very safe</td>\n",
       "      <td>Somewhat satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2474 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    id       day        airline        destination  \\\n",
       "0              0  1351   Tuesday    UNITED INTL             KANSAI   \n",
       "1              1   373    Friday         ALASKA  SAN JOSE DEL CABO   \n",
       "2              2  2820  Thursday          DELTA        LOS ANGELES   \n",
       "3              3  1157   Tuesday      SOUTHWEST        LOS ANGELES   \n",
       "5              5   634  Thursday         ALASKA             NEWARK   \n",
       "...          ...   ...       ...            ...                ...   \n",
       "2472        2804  1475   Tuesday         ALASKA       NEW YORK-JFK   \n",
       "2473        2805  2222  Thursday      SOUTHWEST            PHOENIX   \n",
       "2474        2806  2684    Friday         UNITED            ORLANDO   \n",
       "2475        2807  2549   Tuesday        JETBLUE         LONG BEACH   \n",
       "2476        2808  2162  Saturday  CHINA EASTERN            QINGDAO   \n",
       "\n",
       "        dest_region dest_size boarding_area   dept_time  wait_min  \\\n",
       "0              Asia       Hub  Gates 91-102  2018-12-31     115.0   \n",
       "1     Canada/Mexico     Small   Gates 50-59  2018-12-31     135.0   \n",
       "2           West US       Hub   Gates 40-48  2018-12-31      70.0   \n",
       "3           West US       Hub   Gates 20-39  2018-12-31     190.0   \n",
       "5           East US       Hub   Gates 50-59  2018-12-31     140.0   \n",
       "...             ...       ...           ...         ...       ...   \n",
       "2472        East US       Hub   Gates 50-59  2018-12-31     280.0   \n",
       "2473        West US       Hub   Gates 20-39  2018-12-31     165.0   \n",
       "2474        East US       Hub   Gates 70-90  2018-12-31      92.0   \n",
       "2475        West US     Small    Gates 1-12  2018-12-31      95.0   \n",
       "2476           Asia     Large    Gates 1-12  2018-12-31     220.0   \n",
       "\n",
       "         cleanliness         safety        satisfaction  \n",
       "0              Clean        Neutral      Very satisfied  \n",
       "1              Clean      Very safe      Very satisfied  \n",
       "2            Average  Somewhat safe             Neutral  \n",
       "3              Clean      Very safe  Somewhat satisfied  \n",
       "5     Somewhat clean      Very safe      Very satisfied  \n",
       "...              ...            ...                 ...  \n",
       "2472  Somewhat clean        Neutral  Somewhat satisfied  \n",
       "2473           Clean      Very safe      Very satisfied  \n",
       "2474           Clean      Very safe      Very satisfied  \n",
       "2475           Clean  Somewhat safe      Very satisfied  \n",
       "2476           Clean      Very safe  Somewhat satisfied  \n",
       "\n",
       "[2474 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print rows with consistent categories only\n",
    "airlines[~cat_clean_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "needed-evans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Somewhat clean        1173\n",
       "Clean                  884\n",
       "Average                389\n",
       "Somewhat dirty          26\n",
       "Somewhat satisfied       3\n",
       "Dirty                    2\n",
       "Name: cleanliness, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "airlines['cleanliness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "advanced-submission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>day</th>\n",
       "      <th>airline</th>\n",
       "      <th>destination</th>\n",
       "      <th>dest_region</th>\n",
       "      <th>dest_size</th>\n",
       "      <th>boarding_area</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>wait_min</th>\n",
       "      <th>safety</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cleanliness</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clean</th>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dirty</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somewhat clean</th>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somewhat dirty</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Somewhat satisfied</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Unnamed: 0    id   day  airline  destination  dest_region  \\\n",
       "cleanliness                                                                     \n",
       "Average                    389   389   389      389          389          389   \n",
       "Clean                      884   884   884      884          884          884   \n",
       "Dirty                        2     2     2        2            2            2   \n",
       "Somewhat clean            1173  1173  1173     1173         1173         1173   \n",
       "Somewhat dirty              26    26    26       26           26           26   \n",
       "Somewhat satisfied           3     3     3        3            3            3   \n",
       "\n",
       "                    dest_size  boarding_area  dept_time  wait_min  safety  \\\n",
       "cleanliness                                                                 \n",
       "Average                   389            389        389       389     389   \n",
       "Clean                     884            884        884       884     884   \n",
       "Dirty                       2              2          2         2       2   \n",
       "Somewhat clean           1173           1173       1173      1173    1173   \n",
       "Somewhat dirty             26             26         26        26      26   \n",
       "Somewhat satisfied          3              3          3         3       3   \n",
       "\n",
       "                    satisfaction  \n",
       "cleanliness                       \n",
       "Average                      389  \n",
       "Clean                        884  \n",
       "Dirty                          2  \n",
       "Somewhat clean              1173  \n",
       "Somewhat dirty                26  \n",
       "Somewhat satisfied             3  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking\n",
    "airlines.groupby('cleanliness').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-smell",
   "metadata": {},
   "source": [
    "## Categories of errors\n",
    "\n",
    "In the video exercise, you saw how to address common problems affecting categorical variables in your data, including white spaces and inconsistencies in your categories, and the problem of creating new categories and mapping existing ones to new ones.\n",
    "\n",
    "To get a better idea of the toolkit at your disposal, you will be mapping functions and methods from `pandas` and Python used to address each type of problem.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Map each function/method to the categorical data problem it solves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-purpose",
   "metadata": {},
   "source": [
    "- White spaces and inconsistency\n",
    "\n",
    "```\n",
    ".str.upper()\n",
    ".str.lower()\n",
    ".str.strip()\n",
    "```\n",
    "\n",
    "- Creating or remapping categories\n",
    "\n",
    "```\n",
    ".replace()`\n",
    "pandas.qcut()\n",
    "pandas.cut()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-hours",
   "metadata": {},
   "source": [
    "## Inconsistent categories\n",
    "\n",
    "In this exercise, you'll be revisiting the `airlines` DataFrame from the previous lesson.\n",
    "\n",
    "As a reminder, the DataFrame contains flight metadata such as the airline, the destination, waiting times as well as answers to key questions regarding cleanliness, safety, and satisfaction on the San Francisco Airport.\n",
    "\n",
    "In this exercise, you will examine two categorical columns from this DataFrame, `dest_region` and `dest_size` respectively, assess how to address them and make sure that they are cleaned and ready for analysis. The `pandas` package has been imported as `pd`, and the `airlines` DataFrame is in your environment.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Print the unique values in `dest_region` and `dest_size` respectively.\n",
    "2. From looking at the output, what do you think is the problem with these columns?\n",
    "3. Change the capitalization of all values of `dest_region` to lowercase.\n",
    "4. Replace the `'eur'` with `'europe'` in `dest_region` using the `.replace()` method.\n",
    "5. Strip white spaces from the `dest_size` column using the `.strip()` method.\n",
    "6. Verify that the changes have been into effect by printing the unique values of the columns using `.unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "compatible-commercial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West US                  864\n",
      "East US                  367\n",
      "Europe                   272\n",
      "Midwest US               251\n",
      "Asia                     226\n",
      "Canada/Mexico            198\n",
      "eur                       79\n",
      "EAST US                   69\n",
      "Australia/New Zealand     60\n",
      "Middle East               48\n",
      "Central/South America     22\n",
      "middle east               21\n",
      "Name: dest_region, dtype: int64\n",
      "\n",
      "\n",
      "Hub            1202\n",
      "Medium          457\n",
      "    Hub         226\n",
      "Small           165\n",
      "Hub             122\n",
      "Large           110\n",
      "    Medium       97\n",
      "Medium           46\n",
      "    Small        20\n",
      "Small            15\n",
      "    Large        11\n",
      "Large             6\n",
      "Name: dest_size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].value_counts())\n",
    "print('\\n')\n",
    "print(airlines['dest_size'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "surprised-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "municipal-alliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "west us                  864\n",
      "east us                  436\n",
      "europe                   351\n",
      "midwest us               251\n",
      "asia                     226\n",
      "canada/mexico            198\n",
      "middle east               69\n",
      "australia/new zealand     60\n",
      "central/south america     22\n",
      "Name: dest_region, dtype: int64\n",
      "\n",
      "\n",
      "Hub       1550\n",
      "Medium     600\n",
      "Small      200\n",
      "Large      127\n",
      "Name: dest_size, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].value_counts())\n",
    "print('\\n')\n",
    "print(airlines['dest_size'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-cattle",
   "metadata": {},
   "source": [
    "## Remapping categories\n",
    "\n",
    "To better understand survey respondents from `airlines`, you want to find out if there is a relationship between certain responses and the day of the week and wait time at the gate.\n",
    "\n",
    "The `airlines` DataFrame contains the `day` and `wait_min` columns, which are categorical and numerical respectively. The `day` column contains the exact day a flight took place, and `wait_min` contains the amount of minutes it took travelers to wait at the gate. To make your analysis easier, you want to create two new categorical variables:\n",
    "\n",
    "- `wait_type`: `'short'` for 0-60 min, `'medium'` for 60-180 and `long` for 180+\n",
    "- `day_week`: `'weekday'` if day is in the weekday, `'weekend'` if day is in the weekend.\n",
    "\n",
    "The `pandas` and `numpy` packages have been imported as `pd` and `np`. Let's create some new categorical data!\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Create the ranges and labels for the `wait_type` column mentioned in the description above.\n",
    "2. Create the `wait_type` column by from `wait_min` by using `pd.cut()`, while inputting `label_ranges` and `label_names` in the correct arguments.\n",
    "3. Create the `mapping` dictionary mapping weekdays to `'weekday'` and weekend days to `'weekend'`.\n",
    "4. Create the `day_week` column by using `.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "recovered-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins=label_ranges, labels=label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', 'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-commercial",
   "metadata": {},
   "source": [
    "## Removing titles and taking names\n",
    "\n",
    "While collecting survey respondent metadata in the `airlines` DataFrame, the full name of respondents was saved in the `full_name` column. However upon closer inspection, you found that a lot of the different names are prefixed by honorifics such as `\"Dr.\"`, `\"Mr.\"`, `\"Ms.\"` and `\"Miss\"`.\n",
    "\n",
    "Your ultimate objective is to create two new columns named `first_name` and `last_name`, containing the first and last names of respondents respectively. Before doing so however, you need to remove honorifics.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, alongside `pandas` as `pd`.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Remove `\"Dr.\"`, `\"Mr.\"`, `\"Miss\"` and `\"Ms.\"` from `full_name` by replacing them with an empty string `\"\"` in that order.\n",
    "2. Run the assert statement using `.str.contains()` that tests whether `full_name` still contains any of the honorifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adjacent-nature",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'full_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'full_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7d1c5f60f051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Replace \"Dr.\" with empty string \"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mairlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mairlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dr.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Replace \"Mr.\" with empty string \"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mairlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mairlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mr.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'full_name'"
     ]
    }
   ],
   "source": [
    "# Replace \"Dr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Dr.', '')\n",
    "\n",
    "# Replace \"Mr.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Mr.', '')\n",
    "\n",
    "# Replace \"Miss\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Miss', '')\n",
    "\n",
    "# Replace \"Ms.\" with empty string \"\"\n",
    "airlines['full_name'] = airlines['full_name'].str.replace('Ms.', '')\n",
    "\n",
    "# Assert that full_name has no honorifics\n",
    "assert airlines['full_name'].str.contains('Ms. | Mr. | Miss | Dr.').any() == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-martial",
   "metadata": {},
   "source": [
    "## Keeping it descriptive\n",
    "\n",
    "To further understand travelers' experiences in the San Francisco Airport, the quality assurance department sent out a qualitative questionnaire to all travelers who gave the airport the worst score on all possible categories. The objective behind this questionnaire is to identify common patterns in what travelers are saying about the airport.\n",
    "\n",
    "Their response is stored in the `survey_response` column. Upon a closer look, you realized a few of the answers gave the shortest possible character amount without much substance. In this exercise, you will isolate the responses with a character count higher than **40**, and make sure your new DataFrame contains responses with **40** characters or more using an `assert` statement.\n",
    "\n",
    "The `airlines` DataFrame is in your environment, and `pandas` is imported as `pd`.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Using the `airlines` DataFrame, store the length of each instance in the `survey_response` column in `resp_length` by using `.str.len()`.\n",
    "2. Isolate the rows of `airlines` with `resp_length` higher than `40`.\n",
    "3. Assert that the smallest survey response length in `airlines_survey` is now bigger than 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store length of each row in survey_response column\n",
    "resp_length = airlines['survey_response'].str.len()\n",
    "\n",
    "# Find rows in airlines where resp_length > 40\n",
    "airlines_survey = airlines[resp_length > 40]\n",
    "\n",
    "# Assert minimum survey_response length is > 40\n",
    "assert airlines_survey['survey_response'].str.len().min() > 40\n",
    "\n",
    "# Print new survey_response column\n",
    "print(airlines_survey['survey_response'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
