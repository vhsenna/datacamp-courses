{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "automated-hygiene",
   "metadata": {},
   "source": [
    "## Minimum edit distance\n",
    "\n",
    "In the video exercise, you saw how minimum edit distance is used to identify how similar two strings are. As a reminder, minimum edit distance is the <u>minimum number</u> of steps needed to reach from **String A** to **String B**, with the operations available being:\n",
    "\n",
    "- **Insertion** of a new character.\n",
    "- **Deletion** of an existing character.\n",
    "- **Substitution** of an existing character.\n",
    "- **Transposition** of two existing consecutive characters.\n",
    "\n",
    "_What is the minimum edit distance from `'sign'` to `'sing'`, and which operation(s) gets you there?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-acceptance",
   "metadata": {},
   "source": [
    "1 by transposing `'g'` with `'n'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-meeting",
   "metadata": {},
   "source": [
    "## The cutoff point\n",
    "\n",
    "In this exercise, and throughout this chapter, you'll be working with the `restaurants` DataFrame which has data on various restaurants. Your ultimate goal is to create a restaurant recommendation engine, but you need to first clean your data.\n",
    "\n",
    "This version of `restaurants` has been collected from many sources, where the `cuisine_type` column is riddled with typos, and should contain only `italian`, `american` and `asian` cuisine types. There are so many unique categories that remapping them manually isn't scalable, and it's best to use string similarity instead.\n",
    "\n",
    "Before doing so, you want to establish the cutoff point for the similarity score using the `fuzzywuzzy`'s `process.extract()` function by finding the similarity score of the most _distant_ typo of each category.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Import `process` from `fuzzywuzzy`.\n",
    "2. Store the unique `cuisine_types` into `unique_types`.\n",
    "3. Calculate the similarity of `'asian'`, `'american'`, and `'italian'` to all possible `cuisine_types` using `process.extract()`, while returning all possible matches.\n",
    "4. Take a look at the output, what do you think should be the similarity cutoff point when remapping categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "natural-chemical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('asian', 100), ('asiane', 91), ('asiann', 91), ('asiian', 91), ('asiaan', 91), ('asianne', 83), ('asiat', 80), ('italiann', 72), ('italiano', 72), ('italianne', 72), ('italian', 67), ('amurican', 62), ('american', 62), ('italiaan', 62), ('italiian', 62), ('americann', 57), ('americano', 57), ('ameerican', 57), ('aamerican', 57), ('ameriican', 57), ('amerrican', 57), ('ammericann', 54), ('ameerrican', 54), ('ammereican', 54), ('america', 50), ('merican', 50), ('murican', 50), ('italien', 50), ('americen', 46), ('americin', 46), ('amerycan', 46), ('itali', 40)]\n",
      "[('american', 100), ('americann', 94), ('americano', 94), ('ameerican', 94), ('aamerican', 94), ('ameriican', 94), ('amerrican', 94), ('america', 93), ('merican', 93), ('ammericann', 89), ('ameerrican', 89), ('ammereican', 89), ('amurican', 88), ('americen', 88), ('americin', 88), ('amerycan', 88), ('murican', 80), ('asian', 62), ('asiane', 57), ('asiann', 57), ('asiian', 57), ('asiaan', 57), ('italian', 53), ('asianne', 53), ('italiann', 50), ('italiano', 50), ('italiaan', 50), ('italiian', 50), ('italianne', 47), ('asiat', 46), ('itali', 40), ('italien', 40)]\n",
      "[('italian', 100), ('italiann', 93), ('italiano', 93), ('italiaan', 93), ('italiian', 93), ('italianne', 88), ('italien', 86), ('itali', 83), ('asian', 67), ('asiane', 62), ('asiann', 62), ('asiian', 62), ('asiaan', 62), ('asianne', 57), ('amurican', 53), ('american', 53), ('americann', 50), ('asiat', 50), ('americano', 50), ('ameerican', 50), ('aamerican', 50), ('ameriican', 50), ('amerrican', 50), ('ammericann', 47), ('ameerrican', 47), ('ammereican', 47), ('america', 43), ('merican', 43), ('murican', 43), ('americen', 40), ('americin', 40), ('amerycan', 40)]\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import dataframe\n",
    "restaurants = pd.read_csv('restaurants.csv')\n",
    "\n",
    "# Import process from fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Store the unique values of cuisine_type in unique_types\n",
    "unique_types = restaurants['cuisine_type'].unique()\n",
    "\n",
    "# Calculate similarity of 'asian' to all values of unique_types\n",
    "print(process.extract('asian', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'american' to all values of unique_types\n",
    "print(process.extract('american', unique_types, limit = len(unique_types)))\n",
    "\n",
    "# Calculate similarity of 'italian' to all values of unique_types\n",
    "print(process.extract('italian', unique_types, limit = len(unique_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-forum",
   "metadata": {},
   "source": [
    "## Remapping categories II\n",
    "\n",
    "In the last exercise, you determined that the distance cutoff point for remapping typos of `'american'`, `'asian'`, and `'italian'` cuisine types stored in the `cuisine_type` column should be 80.\n",
    "\n",
    "In this exercise, you're going to put it all together by finding matches with similarity scores equal to or higher than 80 by using `fuzywuzzy.process`'s `extract()` function, for each correct cuisine type, and replacing these matches with it. Remember, when comparing a string with an array of strings using `process.extract()`, the output is a list of tuples where each is formatted like:\n",
    "\n",
    "```\n",
    "(closest match, similarity score, index of match)\n",
    "```\n",
    "\n",
    "The `restaurants` DataFrame is in your environment, and you have access to a `categories` list containing the correct cuisine types (`'italian'`, `'asian'`, and `'american'`).\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Return all of the unique values in the `cuisine_type` column of `restaurants`.\n",
    "2. Okay! Looks like you will need to use some string matching to correct these misspellings!\n",
    "    - As a first step, create a list of `matches`, comparing `'italian'` with the restaurant types listed in the `cuisine_type` column.\n",
    "3. Now you're getting somewhere! Now you can iterate through `matches` to reassign similar entries.\n",
    "    - Within the `for` loop, use an `if` statement to check whether the similarity score in each `match` is greater than or equal to 80.\n",
    "    - If it is, use `.loc` to select rows where `cuisine_type` in `restaurants` is _equal_ to the current match (which is the first element of `match`), and reassign them to be `'italian'`.\n",
    "4. Finally, you'll adapt your code to work with every restaurant type in `categories`.\n",
    "    - Using the variable `cuisine` to iterate through `categories`, embed your code from the previous step in an outer `for` loop.\n",
    "    - Inspect the final result. _This has been done for you_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "younger-midwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america' 'merican' 'amurican' 'americen' 'americann' 'asiane' 'itali'\n",
      " 'asiann' 'murican' 'italien' 'italian' 'asiat' 'american' 'americano'\n",
      " 'italiann' 'ameerican' 'asianne' 'italiano' 'americin' 'ammericann'\n",
      " 'amerycan' 'aamerican' 'ameriican' 'italiaan' 'asiian' 'asiaan'\n",
      " 'amerrican' 'ameerrican' 'ammereican' 'asian' 'italianne' 'italiian']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the unique values of the cuisine_type column\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "green-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italian', 100, 11), ('italian', 100, 24), ('italian', 100, 37), ('italian', 100, 43), ('italian', 100, 44)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "# Inspect the first 5 matches\n",
    "print(matches[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of matches, comparing 'italian' with the cuisine_type column\n",
    "matches = process.extract('italian', restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "# Iterate through the list of matches to italian\n",
    "for match in matches:\n",
    "  # Check whether the similarity score is greater than or equal to 80\n",
    "  if match[1] >= 80:\n",
    "    # Select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "    restaurants.loc[restaurants['cuisine_type'] == match[0]] = 'italian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wireless-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american' 'asian' 'italian']\n"
     ]
    }
   ],
   "source": [
    "categories = ['italian', 'asian', 'american']\n",
    "\n",
    "# Iterate through categories\n",
    "for cuisine in categories:  \n",
    "  # Create a list of matches, comparing cuisine with the cuisine_type column\n",
    "  matches = process.extract(cuisine, restaurants['cuisine_type'], limit=len(restaurants.cuisine_type))\n",
    "\n",
    "  # Iterate through the list of matches\n",
    "  for match in matches:\n",
    "     # Check whether the similarity score is greater than or equal to 80\n",
    "    if match[1] >= 80:\n",
    "      # If it is, select all rows where the cuisine_type is spelled this way, and set them to the correct cuisine\n",
    "      restaurants.loc[restaurants['cuisine_type'] == match[0]] = cuisine\n",
    "    \n",
    "# Inspect the final result\n",
    "print(restaurants['cuisine_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-empire",
   "metadata": {},
   "source": [
    "## To link or not to link?\n",
    "Similar to joins, record linkage is the act of linking data from different sources regarding the same entity. But unlike joins, record linkage does not require exact matches between different pairs of data, and instead can find close matches using string similarity. This is why record linkage is effective when there are no common unique keys between the data sources you can rely upon when linking data sources such as a unique identifier.\n",
    "\n",
    "In this exercise, you will classify each card whether it is a traditional join problem, or a record linkage one.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Classify each card into a problem that requires record linkage or regular joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-poison",
   "metadata": {},
   "source": [
    "- Record linkage\n",
    "    - Two customer DataFrames containing names and adress, one with a unique identifier per customer, one without.\n",
    "    - Merging two basketballs DataFrame, with columns `team_A`, `team_B`, and `time` and differently formatted team names between each DataFrame.\n",
    "    - Using an `address` column to join two DataFrames, with the address in each DataFrame being formatted slightly differently.\n",
    "\n",
    "- Regular joins\n",
    "    - Two basketball DataFrame with a common unique identifier per game.\n",
    "    - Consolidating two DataFrames containing details on DataCamp courses its own unique identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-alliance",
   "metadata": {},
   "source": [
    "## Pairs of restaurants\n",
    "\n",
    "In the last lesson, you cleaned the `restaurants` dataset to make it ready for building a restaurants recommendation engine. You have a new DataFrame named `restaurants_new` with new restaurants to train your model on, that's been scraped from a new data source.\n",
    "\n",
    "You've already cleaned the `cuisine_type` and `city` columns using the techniques learned throughout the course. However you saw duplicates with typos in restaurants names that require record linkage instead of joins with `restaurants`.\n",
    "\n",
    "In this exercise, you will perform the first step in record linkage and generate possible pairs of rows between `restaurants` and `restaurants_new`. Both DataFrames, `pandas` and `recordlinkage` are in your environment.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Instantiate an indexing object by using the `Index()` function from `recordlinkage`.\n",
    "2. Block your pairing on `cuisine_type` by using `indexer`'s' `.block()` method.\n",
    "3. Generate pairs by indexing `restaurants` and `restaurants_new` in that order.\n",
    "4. Now that you've generated your pairs, you've achieved the first step of record linkage. What are the steps remaining to link both restaurants DataFrames, and in what order?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "genetic-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import recordlinkage\n",
    "import recordlinkage\n",
    "\n",
    "# Import dataset\n",
    "restaurants_new = pd.read_csv('restaurants_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bigger-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer and object and find possible pairs\n",
    "indexer = recordlinkage.Index()\n",
    "\n",
    "# Block pairing on cuisine_type\n",
    "indexer.block('cuisine_type')\n",
    "\n",
    "# Generate pairs\n",
    "pairs = indexer.index(restaurants, restaurants_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-palestine",
   "metadata": {},
   "source": [
    "Compare between columns, score the comparison, then link the DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-pharmacology",
   "metadata": {},
   "source": [
    "## Similar restaurants\n",
    "\n",
    "In the last exercise, you generated pairs between `restaurants` and `restaurants_new` in an effort to cleanly merge both DataFrames using record linkage.\n",
    "\n",
    "When performing record linkage, there are different types of matching you can perform between different columns of your DataFrames, including exact matches, string similarities, and more.\n",
    "\n",
    "Now that your pairs have been generated and stored in `pairs`, you will find exact matches in the `city` and `cuisine_type` columns between each pair, and similar strings for each pair in the `rest_name` column. Both DataFrames, `pandas` and `recordlinkage` are in your environment.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Instantiate a comparison object using the `recordlinkage.Compare()` function.\n",
    "2. Use the appropriate `comp_cl` method to find exact matches between the `city` and `cuisine_type` columns of both DataFrames.\n",
    "3. Use the appropriate `comp_cl` method to find similar strings with a `0.8` similarity threshold in the `rest_name` column of both DataFrames.\n",
    "4. Compute the comparison of the pairs by using the `.compute()` method of `comp_cl`.\n",
    "5. Print out `potential_matches`, the columns are the columns being compared, with values being 1 for a match, and 0 for not a match for each pair of rows in your DataFrames. To find potential matches, you need to find rows with more than matching value in a column. You can find them with `potential_matches[potential_matches.sum(axis = 1) >= n]`. Where `n` is the minimum number of columns you want matching to ensure a proper duplicate find, what do you think should the value of `n` be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "monthly-mobile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       city  cuisine_type  name\n",
      "0   0     0             1   0.0\n",
      "1   0     0             1   0.0\n",
      "2   0     0             1   0.0\n",
      "3   0     0             1   0.0\n",
      "4   0     0             1   0.0\n",
      "...     ...           ...   ...\n",
      "323 0     0             1   0.0\n",
      "324 0     0             1   0.0\n",
      "325 0     0             1   0.0\n",
      "327 0     0             1   0.0\n",
      "334 0     0             1   0.0\n",
      "\n",
      "[153 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Create a comparison object\n",
    "comp_cl = recordlinkage.Compare()\n",
    "\n",
    "# Find exact matches on city, cuisine_types \n",
    "comp_cl.exact('city', 'city', label='city')\n",
    "comp_cl.exact('cuisine_type', 'cuisine_type', label='cuisine_type')\n",
    "\n",
    "# Find similar matches of rest_name\n",
    "comp_cl.string('name', 'name', label='name', threshold = 0.8)\n",
    "\n",
    "# Get potential matches and print\n",
    "potential_matches = comp_cl.compute(pairs, restaurants, restaurants_new) \n",
    "print(potential_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-coverage",
   "metadata": {},
   "source": [
    "3 because I need to have matches in all my columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-spectrum",
   "metadata": {},
   "source": [
    "## Getting the right index\n",
    "\n",
    "Here's a DataFrame named `matches` containing potential matches between two DataFrames, `users_1` and `users_2`. Each DataFrame's row indices is stored in `uid_1` and `uid_2` respectively.\n",
    "\n",
    "```\n",
    "             first_name  address_1  address_2  marriage_status  date_of_birth\n",
    "uid_1 uid_2                                                                  \n",
    "0     3              1          1          1                1              0\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "1     3              1          1          1                1              0\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "     ...            ...         ...        ...              ...            ...\n",
    "```\n",
    "\n",
    "How do you extract all values of the `uid_1` index column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-aviation",
   "metadata": {},
   "source": [
    "`matches.index.get_level_values(0)` or `matches.index.get_level_values('uid_1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-southeast",
   "metadata": {},
   "source": [
    "## Linking them together!\n",
    "\n",
    "In the last lesson, you've finished the bulk of the work on your effort to link `restaurants` and `restaurants_new`. You've generated the different pairs of potentially matching rows, searched for exact matches between the `cuisine_type` and `city` columns, but compared for similar strings in the `rest_name` column. You stored the DataFrame containing the scores in `potential_matches`.\n",
    "\n",
    "Now it's finally time to link both DataFrames. You will do so by first extracting all row indices of `restaurants_new` that are matching across the columns mentioned above from `potential_matches`. Then you will subset `restaurants_new` on these indices, then append the non-duplicate values to `restaurants`. All DataFrames are in your environment, alongside `pandas` imported as `pd`.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Isolate instances of `potential_matches` where the row sum is above or equal to 3 by using the `.sum()` method.\n",
    "2. Extract the second column index from `matches`, which represents row indices of matching record from `restaurants_new` by using the `.get_level_values()` method.\n",
    "3. Subset `restaurants_new` for rows that are not in `matching_indices`.\n",
    "4. Append `non_dup` to `restaurants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fluid-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>cuisine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>feast</td>\n",
       "      <td>1949 westwood blvd.</td>\n",
       "      <td>west la</td>\n",
       "      <td>3104750400</td>\n",
       "      <td>chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78</td>\n",
       "      <td>mulberry</td>\n",
       "      <td>17040 ventura blvd.</td>\n",
       "      <td>encino</td>\n",
       "      <td>8189068881</td>\n",
       "      <td>pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>matsuhissa</td>\n",
       "      <td>129 n. la cienega blvd.</td>\n",
       "      <td>beverly hills</td>\n",
       "      <td>3106599639</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>jiraffe</td>\n",
       "      <td>502 santa monica blvd</td>\n",
       "      <td>santa monica</td>\n",
       "      <td>3109176671</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>martha’s</td>\n",
       "      <td>22nd street grill 25 22nd</td>\n",
       "      <td>st. hermosa beach</td>\n",
       "      <td>3103767786</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name                        addr                city  \\\n",
       "0    american     american                    american            american   \n",
       "1    american     american                    american            american   \n",
       "2    american     american                    american            american   \n",
       "3    american     american                    american            american   \n",
       "4    american     american                    american            american   \n",
       "..        ...          ...                         ...                 ...   \n",
       "77         77        feast         1949 westwood blvd.             west la   \n",
       "78         78     mulberry         17040 ventura blvd.              encino   \n",
       "79         79   matsuhissa    129 n. la cienega blvd.        beverly hills   \n",
       "80         80      jiraffe       502 santa monica blvd        santa monica   \n",
       "81         81     martha’s   22nd street grill 25 22nd   st. hermosa beach   \n",
       "\n",
       "         phone  cuisine_type  \n",
       "0     american      american  \n",
       "1     american      american  \n",
       "2     american      american  \n",
       "3     american      american  \n",
       "4     american      american  \n",
       "..         ...           ...  \n",
       "77  3104750400       chinese  \n",
       "78  8189068881         pizza  \n",
       "79  3106599639         asian  \n",
       "80  3109176671   californian  \n",
       "81  3103767786      american  \n",
       "\n",
       "[418 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Isolate potential matches with row sum >=3\n",
    "matches = potential_matches[potential_matches.sum(axis = 1) >= 3]\n",
    "\n",
    "# Get values of second column index of matches\n",
    "matching_indices = matches.index.get_level_values(1)\n",
    "\n",
    "# Subset restaurants_new based on non-duplicate values\n",
    "non_dup = restaurants_new[~restaurants_new.index.isin(matching_indices)]\n",
    "\n",
    "# Append non_dup to restaurants\n",
    "full_restaurants = restaurants.append(non_dup)\n",
    "full_restaurants"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
