{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noted-karaoke",
   "metadata": {},
   "source": [
    "## Try another name\n",
    "\n",
    "You are still working on your Twitter sentiment analysis. You analyze now some things that caught your attention. You noticed that there are email addresses inserted in some tweets. Now, you are curious to find out which is the most common name.\n",
    "\n",
    "You want to extract the first part of the email. E.g. if you have the email `marysmith90@gmail.com`, you are only interested `in marysmith90`.\n",
    "You need to match the entire expression. So you make sure to extract only names present in emails. Also, you are only interested in names containing upper (e.g. A,B, Z) or lowercase letters (e.g. a, d, z) and numbers.\n",
    "\n",
    "The list `sentiment_analysis` containing the text of three tweets as well as the `re` module were loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Complete the regex to match the email capturing only the name part. The name part appears before the `@`.\n",
    "2. Find all matches of the regex in each element of `sentiment_analysis` analysis. Assign it to the variable `email_matched`.\n",
    "3. Complete the `.format()` method to print the results captured in each element of `sentiment_analysis` analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defined-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sentiment_analysis = ['Just got ur newsletter, those fares really are unbelievable. Write to statravelAU@gmail.com or statravelpo@hotmail.com. They have amazing prices',\n",
    "                      'I should have paid more attention when we covered photoshop in my webpage design class in undergrad. Contact me Hollywoodheat34@msn.net.',\n",
    "                      'hey missed ya at the meeting. Read your email! msdrama098@hotmail.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists of users found in this tweet: ['statravelAU', 'statravelpo']\n",
      "Lists of users found in this tweet: ['Hollywoodheat34']\n",
      "Lists of users found in this tweet: ['msdrama098']\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches email\n",
    "regex_email = r'([a-zA-Z0-9]+)@\\S+'\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in each tweet\n",
    "    email_matched = re.findall(regex_email, tweet)\n",
    "\n",
    "    # Complete the format method to print the results\n",
    "    print('Lists of users found in this tweet: {}'.format(email_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-alexander",
   "metadata": {},
   "source": [
    "## Flying home\n",
    "\n",
    "Your boss assigned you to a small project. They are performing an analysis of the travels people made to attend business meetings. You are given a dataset with only the email subjects for each of the people traveling.\n",
    "\n",
    "You learn that the text followed a pattern. Here is an example:\n",
    "\n",
    "`Here you have your boarding pass LA4214 AER-CDB 06NOV`.\n",
    "\n",
    "You need to extract the information about the flight:\n",
    "\n",
    "- The two letters indicate the airline (e.g `LA`),\n",
    "- The 4 numbers are the flight number (e.g. `4214`).\n",
    "- The three letters correspond to the departure (e.g `AER`),\n",
    "- The destination (`CDB`),\n",
    "- The date (`06NOV`) of the flight.\n",
    "\n",
    "All letters are always uppercase.\n",
    "\n",
    "The variable `flight` containing one email subject was loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Import the `re` module.\n",
    "2. Complete the regular expression to match and capture all the flight information required. Only the first parenthesis were placed for you.\n",
    "3. Find all the matches corresponding to each piece of information about the flight. Assign it to `flight_matches`.\n",
    "4. Complete the format method with the elements contained in `flight_matches`. In the first line print the airline, and the flight number. In the second line, the departure and destination. In the third line, the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intensive-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = 'Subject: You are now ready to fly. Here you have your boarding pass IB3723 AMS-MAD 06OCT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dimensional-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: IB Flight number: 3723\n",
      "Departure: AMS Destination: MAD\n",
      "Date: 06OCT\n"
     ]
    }
   ],
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write regex to capture information of the flight\n",
    "regex = r'([A-Z]{2})(\\d{4})\\s([A-Z]{3})-([A-Z]{3})\\s(\\d{2}[A-Z]{3})'\n",
    "\n",
    "# Find all matches of the flight information\n",
    "flight_matches = re.findall(regex, flight)\n",
    "\n",
    "# Print the matches\n",
    "print('Airline: {} Flight number: {}'.format(flight_matches[0][0], flight_matches[0][1]))\n",
    "print('Departure: {} Destination: {}'.format(flight_matches[0][2], flight_matches[0][3]))\n",
    "print('Date: {}'.format(flight_matches[0][4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-latvia",
   "metadata": {},
   "source": [
    "## Love it!\n",
    "\n",
    "You are still working on the Twitter sentiment analysis project. First, you want to identify positive tweets about movies and concerts.\n",
    "\n",
    "You plan to find all the sentences that contain the words _love_, _like_, or _enjoy_ and capture that word. You will limit the tweets by focusing on those that contain the words _movie_ or _concert_ by keeping the word in another group. You will also save the movie or concert name.\n",
    "\n",
    "For example, if you have the sentence: `I love the movie Avengers`. You match and capture `love`. You need to match and capture `movie`. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "The list `sentiment_analysis` containing the text of three tweets and the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Complete the regular expression to capture the words `love` or `like` or `enjoy`. Match and capture the words `movie` or `concert`. Match and capture anything appearing until the `.`.\n",
    "2. Find all matches of the regex in each element of `sentiment_analysis`. Assign them to `positive_matches`.\n",
    "3. Complete the `.format()` method to print out the results contained in `positive_matches` for each element in `sentiment_analysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "duplicate-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['I totally love the concert The Book of Souls World Tour. It kinda amazing!',\n",
    "                      'I enjoy the movie Wreck-It Ralph. I watched with my boyfriend.',\n",
    "                      \"I still like the movie Wish Upon a Star. Too bad Disney doesn't show it anymore.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "simple-given",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive comments found [('love', 'concert', 'The Book of Souls World Tour')]\n",
      "Positive comments found [('enjoy', 'movie', 'Wreck-It Ralph')]\n",
      "Positive comments found [('like', 'movie', 'Wish Upon a Star')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_positive = r'(love|like|enjoy).+?(movie|concert)\\s(.+?)\\.'\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in tweet\n",
    "    positive_matches = re.findall(regex_positive, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print('Positive comments found {}'.format(positive_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-adolescent",
   "metadata": {},
   "source": [
    "## Ugh! Not for me!\n",
    "\n",
    "After finding positive tweets, you want to do it for negative tweets. Your plan now is to find sentences that contain the words _hate_, _dislike_ or _disapprove_. You will again save the _movie_ or _concert_ name. You will get the tweet containing the words movie or concert but this time, you don't plan to save the word.\n",
    "\n",
    "For example, if you have the sentence: `I dislike the movie Avengers a lot.`. You match and capture `dislike`. You will match but not capture the word `movie`. Afterwards, you match and capture anything until the dot.\n",
    "\n",
    "The list `sentiment_analysis` containing the text of three tweets as well as the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Complete the regular expression to capture the words `hate` or `dislike` or `disapprove`. Match but don't capture the words `movie` or `concert`. Match and capture anything appearing until the `.`.\n",
    "2. Find all matches of the regex in each element of `sentiment_analysis`. Assign them to `negative_matches`.\n",
    "3. Complete the `.format()` method to print out the results contained in `negative_matches` for each element in `sentiment_analysis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imported-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['That was horrible! I really dislike the movie The cabin and the ant. So boring.',\n",
    "                      \"I disapprove the movie Honest with you. It's full of cliches.\",\n",
    "                      'I dislike very much the concert After twelve Tour. The sound was horrible.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "several-diesel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative comments found [('dislike', 'The cabin and the ant')]\n",
      "Negative comments found [('disapprove', 'Honest with you')]\n",
      "Negative comments found [('dislike', 'After twelve Tour')]\n"
     ]
    }
   ],
   "source": [
    "# Write a regex that matches sentences with the optional words\n",
    "regex_negative = r'(hate|dislike|disapprove).+?(?:movie|concert)\\s(.+?)\\.'\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find all matches of regex in tweet\n",
    "    negative_matches = re.findall(regex_negative, tweet)\n",
    "    \n",
    "    # Complete format to print out the results\n",
    "    print('Negative comments found {}'.format(negative_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-advertising",
   "metadata": {},
   "source": [
    "## Parsing PDF files\n",
    "\n",
    "You now need to work on another small project you have been delaying. Your company gave you some PDF files of signed contracts. The goal of the project is to create a database with the information you parse from them. Three of these columns should correspond to the day, month, and year when the contract was signed.\n",
    "The dates appear as Signed on `05/24/2016` (`05` indicating the month, `24` the day). You decide to use capturing groups to extract this information. Also, you would like to retrieve that information so you can store it separately in different variables.\n",
    "\n",
    "You decide to do a proof of concept.\n",
    "\n",
    "The variable `contract` containing the text of one contract and the `re` module are already loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Write a regex that captures the month, day, and year in which the `contract` was signed. Scan `contract` for matches.\n",
    "2. Assign each captured group to the corresponding keys in the dictionary.\n",
    "3. Complete the positional method to print out the captured groups. Use the values corresponding to each key in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "married-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = 'Provider will invoice Client for Services performed within 30 days of performance.  Client will pay Provider as set forth in each Statement of Work within 30 days of receipt and acceptance of such invoice. It is understood that payments to Provider for services rendered shall be made in full as agreed, without any deductions for taxes of any kind whatsoever, in conformity with Providerâ€™s status as an independent contractor. Signed on 03/25/2001.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "binary-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our first contract is dated back to 2001. Particularly, the day 25 of the month 03.\n"
     ]
    }
   ],
   "source": [
    "# Write regex and scan contract to capture the dates described\n",
    "regex_dates = r'Signed\\son\\s(\\d{2})/(\\d{2})/(\\d{4})'\n",
    "dates = re.search(regex_dates, contract)\n",
    "\n",
    "# Assign to each key the corresponding match\n",
    "signature = {'day': dates.group(2),\n",
    "             'month': dates.group(1),\n",
    "             'year': dates.group(3)}\n",
    "\n",
    "# Complete the format method to print-out\n",
    "print('Our first contract is dated back to {data[year]}. Particularly, the day {data[day]} of the month {data[month]}.'.format(data=signature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-concentrate",
   "metadata": {},
   "source": [
    "## Close the tag, please!\n",
    "\n",
    "In the meantime, you are working on one of your other projects. The company is going to develop a new product. It will help developers automatically check the code they are writing. You need to write a short script for checking that every HTML tag that is open has its proper closure.\n",
    "\n",
    "You have an example of a string containing HTML tags:\n",
    "\n",
    "`<title>The Data Science Company</title>`\n",
    "\n",
    "You learn that an opening HTML tag is always at the beginning of the string. It appears inside `<>`. A closing tag also appears inside `<>`, but it is preceded by `/`.\n",
    "\n",
    "You also remember that capturing groups can be referenced using numbers, e.g `\\4`.\n",
    "\n",
    "The list `html_tags`, containing three strings with HTML tags, and the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Complete the regex in order to match closed HTML tags. Find if there is a match in each string of the list `html_tags`. Assign the result to `match_tag`.\n",
    "2. If a match is found, print the first group captured and saved in `match_tag`.\n",
    "3. If no match is found, complete the regex to match only the text inside the HTML tag. Assign it to `notmatch_tag`.\n",
    "4. Print the first group captured by the regex and save it in `notmatch_tag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "resident-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_tags = ['<body>Welcome to our course! It would be an awesome experience</body>',\n",
    "             '<article>To be a data scientist, you need to have knowledge in statistics and mathematics</article>',\n",
    "             '<nav>About me Links Contact me!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "engaging-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your tag body is closed\n",
      "Your tag article is closed\n",
      "Close your nav tag!\n"
     ]
    }
   ],
   "source": [
    "for string in html_tags:\n",
    "    # Complete the regex and find if it matches a closed HTML tags\n",
    "    match_tag =  re.match(r'<(\\w+)>.*?</\\1>', string)\n",
    " \n",
    "    if match_tag:\n",
    "        # If it matches print the first group capture\n",
    "        print('Your tag {} is closed'.format(match_tag.group(1))) \n",
    "    else:\n",
    "        # If it doesn't match capture only the tag \n",
    "        notmatch_tag = re.match(r'<(\\w+)>', string)\n",
    "        # Print the first group capture\n",
    "        print('Close your {} tag!'.format(notmatch_tag.group(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-business",
   "metadata": {},
   "source": [
    "## Reeepeated characters\n",
    "\n",
    "Back to your sentiment analysis! Your next task is to replace elongated words that appear in the tweets. We define an elongated word as a word that contains a repeating character twice or more times. e.g. \"**Awesoooome**\".\n",
    "\n",
    "Replacing those words is very important since a classifier will treat them as a different term from the source words lowering their frequency.\n",
    "\n",
    "To find them, you will use capturing groups and reference them back using numbers. E.g `\\4`.\n",
    "\n",
    "If you want to find a match for `Awesoooome`. You first need to capture `Awes`. Then, match `o` and reference the same character back, and then, `me`.\n",
    "\n",
    "The list `sentiment_analysis`, containing the text of three tweets, and the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Complete the regular expression to match an elongated word as described.\n",
    "2. Search the elements in `sentiment_analysis` list to find out if they contain elongated words. Assign the result to `match_elongated`.\n",
    "3. Assign the captured group number zero to the variable `elongated_word`.\n",
    "4. Print the result contained in the variable `elongated_word`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "integrated-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = ['@marykatherine_q i know! I heard it this morning and wondered the same thing. Moscooooooow is so behind the times',\n",
    "                      'Staying at a friends house...neighborrrrrrrs are so loud-having a party',\n",
    "                      'Just woke up an already have read some e-mail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "domestic-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elongated word found: Moscooooooow\n",
      "Elongated word found: neighborrrrrrrs\n",
      "No elongated word found\n"
     ]
    }
   ],
   "source": [
    "# Complete the regex to match an elongated word\n",
    "regex_elongated = r'\\w*(\\w)\\1\\w*'\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "    # Find if there is a match in each tweet \n",
    "    match_elongated = re.search(regex_elongated, tweet)\n",
    "    \n",
    "    if match_elongated:\n",
    "        # Assign the captured group zero \n",
    "        elongated_word = match_elongated.group(0)\n",
    "        \n",
    "        # Complete the format method to print the word\n",
    "        print('Elongated word found: {word}'.format(word=elongated_word))\n",
    "    else:\n",
    "        print('No elongated word found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-equality",
   "metadata": {},
   "source": [
    "## Surrounding words\n",
    "\n",
    "Now, you want to perform some visualizations with your `sentiment_analysis` dataset. You are interested in the words surrounding `python`. You want to count how many times a specific words appears right before and after it.\n",
    "\n",
    "**Positive lookahead** (`?=`) makes sure that first part of the expression is followed by the lookahead expression. **Positive lookbehind** (`?<=`) returns all matches that are preceded by the specified pattern.\n",
    "\n",
    "The variable `sentiment_analysis`, containing the text of one tweet, and the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Get all the words that are followed by the word `python` in `sentiment_analysis`. Print out the word found.\n",
    "2. Get all the words that are preceded by the word `python` or `Python` in `sentiment_analysis`. Print out the words found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "spatial-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis = 'You need excellent python skills to be a data scientist. Must be! Excellent python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "minus-structure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['excellent', 'Excellent']\n"
     ]
    }
   ],
   "source": [
    "# Positive lookahead\n",
    "look_ahead = re.findall(r'\\w+(?=\\spython)', sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "look_ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "phantom-third",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skills']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positive lookbehind\n",
    "look_behind = re.findall(r'(?<=[Pp]ython\\s)\\w+', sentiment_analysis)\n",
    "\n",
    "# Print out\n",
    "look_behind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-break",
   "metadata": {},
   "source": [
    "## Filtering phone numbers\n",
    "\n",
    "Now, you need to write a script for a cell-phone searcher. It should scan a list of phone numbers and return those that meet certain characteristics.\n",
    "\n",
    "The phone numbers in the list have the structure:\n",
    "\n",
    "- Optional area code: 3 numbers\n",
    "- Prefix: 4 numbers\n",
    "- Line number: 6 numbers\n",
    "- Optional extension: 2 numbers\n",
    "\n",
    "E.g. `654-8764-439434-01`.\n",
    "\n",
    "You decide to use `.findall()` and the non-capturing group's negative lookahead `(?!)` and negative lookbehind `(?<!)`.\n",
    "\n",
    "The list `cellphones`, containing three phone numbers, and the `re` module are loaded in your session.\n",
    "\n",
    "Instructions\n",
    "\n",
    "1. Get all cell phones numbers that are not preceded by the optional area code.\n",
    "2. Get all the cell phones numbers that are not followed by the optional extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "exposed-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellphones = ['4564-646464-01', '345-5785-544245', '6476-579052-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "automated-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4564-646464-01']\n",
      "[]\n",
      "['6476-579052-01']\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not preceded by area code\n",
    "    number = re.findall(r'(?<!\\d{3}-)\\d{4}-\\d{6}-\\d{2}', phone)\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "international-assault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['345-5785-544245']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for phone in cellphones:\n",
    "    # Get all phone numbers not followed by optional extension\n",
    "    number = re.findall(r'\\d{3}-\\d{4}-\\d{6}(?!-\\d{2})', phone)\n",
    "    print(number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
